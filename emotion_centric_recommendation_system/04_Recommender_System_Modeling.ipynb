{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 5px; height: 50px\"> \n",
    "\n",
    "#   Personalizing Music Video Recommendations with Emotional Intelligence\n",
    "\n",
    "> Capstone Project: Lionel Foo\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b> Notebook: 04 Building an Emotion-based Music Video Recommendation System </b>\n",
    "\n",
    "<b> The objective is to design an emotion-centric music video recommendation system. </b>\n",
    "\n",
    "Music holds a profound capacity to elicit human emotions. [1] The field of music recommendation is particularly influenced by this emotional aspect, as individuals often gravitate towards music that mirrors their current emotional state. [2] [3]\n",
    "\n",
    "The proposed system will analyze YouTube users’ comments to discern their emotional state and subsequently recommend Youtube music videos. These recommendations aim to either resonate with the users’ current emotional state or aid them in navigating through negative emotions.\n",
    "\n",
    "The system will prioritize user well-being by suggesting songs that harmonize with their current mood. It will evaluate users’ emotional needs based on their comments and recommend the most “beneficial” music videos instead of the most “matched” ones. A beneficial music video is defined by two criteria:\n",
    "* It aligns with the user’s emotional state, thereby fulfilling their emotional needs.\n",
    "* If the user’s overall mood is negative, the recommended music video should have the potential to uplift the user’s mood. This implies that the music should be slightly more positive than the user’s current mood. However, to prevent causing emotional discomfort or resistance to the recommendation, the degree of positivity should be delicately balanced. [4]\n",
    "\n",
    "This approach ensures that the system is not just recommending music videos, but also contributing to the users’ emotional well-being.\n",
    "\n",
    "<font size=\"1.5\">\n",
    "\n",
    "References: \n",
    "\n",
    "[1] University of Turku. Music can evoke strong emotions - the same melody can lead to shivers down the spine or feelings of joy. <br>https://www.utu.fi/en/news/press-release/music-can-evoke-strong-emotions-the-same-melody-can-lead-to-shivers-down-the-spine-or-feelings-of-joy\n",
    "\n",
    "[2] IEEE Xplore. Mood-Based Music Recommendation System Using Supervised Learning. <br>https://ieeexplore.ieee.org/document/9256342\n",
    "\n",
    "[3] Springer Link. Induced Emotion-Based Music Recommendation through Reinforcement Learning. <br>https://link.springer.com/chapter/10.1007/978-3-030-35288-2_20\n",
    "\n",
    "[4] Science Direct. An Emotion-based Personalized Music Recommendation Framework for Emotion Improvement. <br>https://www.sciencedirect.com/science/article/abs/pii/S0306457322003570\n",
    "\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<b> 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports: standard\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "from scipy.spatial import KDTree\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<b> 2. Predicting emotions of each Scraped Youtube Comment </b>\n",
    "* In notebook 2C we build an emotion-centric text-based classifier (RNN with GloVe Word Embeddings) that can classify text into five classes: Sadness, Joy, Love, Anger, and Fear.\n",
    "\n",
    "<b> Step Outline </b>\n",
    "\n",
    "1. **Load the Model and Tokenizer:** load the pre-trained emotion classifier model and the tokenizer used during the model training.\n",
    "2. **Import YouTube Comments:** import a dataset of scraped and cleaned YouTube comments. This dataset contains approx 50,000 comments, with 1,000 comments each from a list of 100 music videos.\n",
    "3. **Prepare Text for Model:** create a new column ‘text_to_model’ that replicates the ‘text’ column. This column will be used to prepare the text data for the model. Tokenize the text and pad the sequences to ensure they all have the same length.\n",
    "4. **Predict Emotions:** use the emotion classifier model to predict the emotions expressed in the comments. The model outputs both the predicted labels and the probabilities for each emotion class.\n",
    "5. **Map Labels to Emotions:** map the predicted labels to their corresponding emotions using a predefined dictionary.\n",
    "6. **Clean Up DataFrame:** drop the ‘text_to_model’ column from the DataFrame as it’s no longer needed.\n",
    "7. **Final Output:** The final output is a DataFrame that includes the original YouTube comments along with the predicted emotion and the probabilities for each emotion class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "emotion_classifier_model = load_model('Model/model_emotions.keras')\n",
    "\n",
    "# Load the tokenizer\n",
    "with open('Model/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>like_count</th>\n",
       "      <th>text</th>\n",
       "      <th>video_id</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Royalchess1</td>\n",
       "      <td>2024-02-24T09:02:54Z</td>\n",
       "      <td>0</td>\n",
       "      <td>ms miley i have alot of mixed emotions while w...</td>\n",
       "      <td>G7KNmW9a75Y</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@mikerooney7600</td>\n",
       "      <td>2024-02-24T09:01:41Z</td>\n",
       "      <td>0</td>\n",
       "      <td>i love this song it makes every day better</td>\n",
       "      <td>G7KNmW9a75Y</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Ganesh-zs1iv</td>\n",
       "      <td>2024-02-24T08:07:13Z</td>\n",
       "      <td>0</td>\n",
       "      <td>it is feb and still i am watching it</td>\n",
       "      <td>G7KNmW9a75Y</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            author            updated_at  like_count  \\\n",
       "0     @Royalchess1  2024-02-24T09:02:54Z           0   \n",
       "1  @mikerooney7600  2024-02-24T09:01:41Z           0   \n",
       "2    @Ganesh-zs1iv  2024-02-24T08:07:13Z           0   \n",
       "\n",
       "                                                text     video_id  public  \n",
       "0  ms miley i have alot of mixed emotions while w...  G7KNmW9a75Y    True  \n",
       "1         i love this song it makes every day better  G7KNmW9a75Y    True  \n",
       "2               it is feb and still i am watching it  G7KNmW9a75Y    True  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import cleaned youtube comments\n",
    "youtube_comments = pd.read_csv(\"Data/youtube_comments_clean.csv\")\n",
    "youtube_comments.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check there are no null rows under 'text' columns\n",
    "youtube_comments['text'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>comment_origin_video_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Royalchess1</td>\n",
       "      <td>G7KNmW9a75Y</td>\n",
       "      <td>ms miley i have alot of mixed emotions while w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@mikerooney7600</td>\n",
       "      <td>G7KNmW9a75Y</td>\n",
       "      <td>i love this song it makes every day better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Ganesh-zs1iv</td>\n",
       "      <td>G7KNmW9a75Y</td>\n",
       "      <td>it is feb and still i am watching it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            author comment_origin_video_id  \\\n",
       "0     @Royalchess1             G7KNmW9a75Y   \n",
       "1  @mikerooney7600             G7KNmW9a75Y   \n",
       "2    @Ganesh-zs1iv             G7KNmW9a75Y   \n",
       "\n",
       "                                                text  \n",
       "0  ms miley i have alot of mixed emotions while w...  \n",
       "1         i love this song it makes every day better  \n",
       "2               it is feb and still i am watching it  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping unnecessary columns, renaming 'video_id', and organising relevant columns\n",
    "youtube_comments.drop(columns=['updated_at', 'like_count', 'public'], inplace=True)\n",
    "youtube_comments.rename(columns={'video_id': 'comment_origin_video_id'}, inplace=True)\n",
    "youtube_comments = youtube_comments[['author', 'comment_origin_video_id', 'text']]\n",
    "youtube_comments.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'text_to_model' that replicates 'text'\n",
    "youtube_comments['text_to_model'] = youtube_comments['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and pad sequences\n",
    "youtube_comments['text_to_model'] = youtube_comments['text_to_model'].apply(lambda x: tokenizer.texts_to_sequences([x]))\n",
    "youtube_comments['text_to_model'] = youtube_comments['text_to_model'].apply(lambda x: pad_sequences(x, maxlen=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1745/1745 [==============================] - 6s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict labels and probabilities\n",
    "predictions = emotion_classifier_model.predict(np.concatenate(youtube_comments['text_to_model'].values))\n",
    "youtube_comments['label'] = predictions.argmax(axis=1)\n",
    "youtube_comments['probability_sadness'] = predictions[:, 0]\n",
    "youtube_comments['probability_joy'] = predictions[:, 1]\n",
    "youtube_comments['probability_love'] = predictions[:, 2]\n",
    "youtube_comments['probability_anger'] = predictions[:, 3]\n",
    "youtube_comments['probability_fear'] = predictions[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map labels to emotions\n",
    "emotion_dict = {0: 'Sadness', 1: 'Joy', 2: 'Love', 3: 'Anger', 4: 'Fear'}\n",
    "youtube_comments['emotion'] = youtube_comments['label'].map(emotion_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>comment_origin_video_id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_to_model</th>\n",
       "      <th>label</th>\n",
       "      <th>probability_sadness</th>\n",
       "      <th>probability_joy</th>\n",
       "      <th>probability_love</th>\n",
       "      <th>probability_anger</th>\n",
       "      <th>probability_fear</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55826</th>\n",
       "      <td>@69jdwalt</td>\n",
       "      <td>vhumOLNSSJY</td>\n",
       "      <td>no one should be taken over after this is a ho...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>0.040106</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.953556</td>\n",
       "      <td>0.003682</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55827</th>\n",
       "      <td>@ZShorts-gf7tz</td>\n",
       "      <td>vhumOLNSSJY</td>\n",
       "      <td>absolutely amazing song nf is not just talente...</td>\n",
       "      <td>[[898, 33, 482, 605, 22, 28, 44, 210, 63, 98, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.996426</td>\n",
       "      <td>0.003328</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55828</th>\n",
       "      <td>@TurdFPh.D</td>\n",
       "      <td>vhumOLNSSJY</td>\n",
       "      <td>people rely on you people you have never met y...</td>\n",
       "      <td>[[13, 108, 279, 38, 1421, 3, 100, 28, 4, 1102,...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.059979</td>\n",
       "      <td>0.044040</td>\n",
       "      <td>0.033233</td>\n",
       "      <td>0.236552</td>\n",
       "      <td>0.626196</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author comment_origin_video_id  \\\n",
       "55826       @69jdwalt             vhumOLNSSJY   \n",
       "55827  @ZShorts-gf7tz             vhumOLNSSJY   \n",
       "55828      @TurdFPh.D             vhumOLNSSJY   \n",
       "\n",
       "                                                    text  \\\n",
       "55826  no one should be taken over after this is a ho...   \n",
       "55827  absolutely amazing song nf is not just talente...   \n",
       "55828  people rely on you people you have never met y...   \n",
       "\n",
       "                                           text_to_model  label  \\\n",
       "55826  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      3   \n",
       "55827  [[898, 33, 482, 605, 22, 28, 44, 210, 63, 98, ...      1   \n",
       "55828  [[13, 108, 279, 38, 1421, 3, 100, 28, 4, 1102,...      4   \n",
       "\n",
       "       probability_sadness  probability_joy  probability_love  \\\n",
       "55826             0.001944         0.040106          0.000712   \n",
       "55827             0.000020         0.996426          0.003328   \n",
       "55828             0.059979         0.044040          0.033233   \n",
       "\n",
       "       probability_anger  probability_fear emotion  \n",
       "55826           0.953556          0.003682   Anger  \n",
       "55827           0.000060          0.000166     Joy  \n",
       "55828           0.236552          0.626196    Fear  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youtube_comments.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'text_to_model' column from the DataFrame:\n",
    "youtube_comments = youtube_comments.drop(columns = 'text_to_model')\n",
    "# Reset index:\n",
    "youtube_comments = youtube_comments.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data frame with emotions classified youtube comments as csv:\n",
    "youtube_comments.to_csv('Data/youtube_comments_emotion_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<b> 3. analyze the emotional content of music videos based on their lyrics </b>\n",
    "\n",
    "<b> Step Outline </b>\n",
    "\n",
    "1. **Import Music Video Transcripts:** import a dataset of cleaned and chunked transcripts (in Notebook 3A) from 100 popular music videos from the 2020s.\n",
    "2. **Prepare Text for Model:** create a new column ‘text_to_model’ that replicates the ‘transcript’ column. This column will be used to prepare the text data for the model. tokenize the text and pad the sequences to ensure they all have the same length.\n",
    "3. **Predict Emotions:** use the emotion classifier model to predict the emotions expressed in the transcripts. The model outputs both the predicted labels and the probabilities for each emotion class.\n",
    "4. **Map Labels to Emotions:** map the predicted labels to their corresponding emotions using predefined dictionary above.\n",
    "5. **Combining back the chunks**\n",
    "- (a) **Concatenate Transcripts:** concatenate the transcripts for each video (same video_id) into a single string.\n",
    "- (b) **Average Probabilities:** calculate the average probability for each emotion class for each video.\n",
    "- (c) **Update Labels:** update the label for each video to the emotion class with the highest average probability.\n",
    "- (d) **Map Labels to Emotions:** map the updated labels to their corresponding emotions using the predefined dictionary.\n",
    "6. **Clean Up Dataframe:** drop duplicate rows from the DataFrame and reset the index.\n",
    "7. **Final Output** The final output is a DataFrame that includes the transcripts of the music videos along with the predicted emotion and the average probabilities for each emotion class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G7KNmW9a75Y</td>\n",
       "      <td>we were good  we were gold  kind of dream that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G7KNmW9a75Y</td>\n",
       "      <td>started to cry but then remembered i  i can bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G7KNmW9a75Y</td>\n",
       "      <td>yeah i can love me better than you can  can lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                         transcript\n",
       "0  G7KNmW9a75Y  we were good  we were gold  kind of dream that...\n",
       "1  G7KNmW9a75Y  started to cry but then remembered i  i can bu...\n",
       "2  G7KNmW9a75Y  yeah i can love me better than you can  can lo..."
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import cleaned youtube comments\n",
    "youtube_mv_transcripts = pd.read_csv(\"Data/youtube_mv_transcript_clean.csv\")\n",
    "youtube_mv_transcripts.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>transcript</th>\n",
       "      <th>text_to_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G7KNmW9a75Y</td>\n",
       "      <td>we were good  we were gold  kind of dream that...</td>\n",
       "      <td>we were good  we were gold  kind of dream that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G7KNmW9a75Y</td>\n",
       "      <td>started to cry but then remembered i  i can bu...</td>\n",
       "      <td>started to cry but then remembered i  i can bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G7KNmW9a75Y</td>\n",
       "      <td>yeah i can love me better than you can  can lo...</td>\n",
       "      <td>yeah i can love me better than you can  can lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                         transcript  \\\n",
       "0  G7KNmW9a75Y  we were good  we were gold  kind of dream that...   \n",
       "1  G7KNmW9a75Y  started to cry but then remembered i  i can bu...   \n",
       "2  G7KNmW9a75Y  yeah i can love me better than you can  can lo...   \n",
       "\n",
       "                                       text_to_model  \n",
       "0  we were good  we were gold  kind of dream that...  \n",
       "1  started to cry but then remembered i  i can bu...  \n",
       "2  yeah i can love me better than you can  can lo...  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column 'text_to_model' that replicates 'text'\n",
    "youtube_mv_transcripts['text_to_model'] = youtube_mv_transcripts['transcript']\n",
    "youtube_mv_transcripts.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and pad sequences\n",
    "youtube_mv_transcripts['text_to_model'] = youtube_mv_transcripts['text_to_model'].apply(lambda x: tokenizer.texts_to_sequences([x]))\n",
    "youtube_mv_transcripts['text_to_model'] = youtube_mv_transcripts['text_to_model'].apply(lambda x: pad_sequences(x, maxlen=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict labels and probabilities\n",
    "predictions_mv = emotion_classifier_model.predict(np.concatenate(youtube_mv_transcripts['text_to_model'].values))\n",
    "youtube_mv_transcripts['label'] = predictions_mv.argmax(axis=1)\n",
    "youtube_mv_transcripts['probability_sadness'] = predictions_mv[:, 0]\n",
    "youtube_mv_transcripts['probability_joy'] = predictions_mv[:, 1]\n",
    "youtube_mv_transcripts['probability_love'] = predictions_mv[:, 2]\n",
    "youtube_mv_transcripts['probability_anger'] = predictions_mv[:, 3]\n",
    "youtube_mv_transcripts['probability_fear'] = predictions_mv[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map labels to emotions\n",
    "youtube_mv_transcripts['emotion'] = youtube_mv_transcripts['label'].map(emotion_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>transcript</th>\n",
       "      <th>text_to_model</th>\n",
       "      <th>label</th>\n",
       "      <th>probability_sadness</th>\n",
       "      <th>probability_joy</th>\n",
       "      <th>probability_love</th>\n",
       "      <th>probability_anger</th>\n",
       "      <th>probability_fear</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G7KNmW9a75Y</td>\n",
       "      <td>we were good  we were gold  kind of dream that...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 77, 120, 117, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3.811742e-02</td>\n",
       "      <td>0.049064</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>9.033179e-01</td>\n",
       "      <td>8.883808e-03</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G7KNmW9a75Y</td>\n",
       "      <td>started to cry but then remembered i  i can bu...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 177, 4, 639, 22, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.435994e-03</td>\n",
       "      <td>0.955003</td>\n",
       "      <td>0.011286</td>\n",
       "      <td>1.009263e-02</td>\n",
       "      <td>2.118289e-02</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G7KNmW9a75Y</td>\n",
       "      <td>yeah i can love me better than you can  can lo...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1420, 1, 44, 8...</td>\n",
       "      <td>0</td>\n",
       "      <td>7.336176e-01</td>\n",
       "      <td>0.258982</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>6.150512e-03</td>\n",
       "      <td>4.139581e-04</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G7KNmW9a75Y</td>\n",
       "      <td>no remorse  no regret  i forgive every word yo...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 93, 3268, 93, 1325, 1, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>5.313131e-03</td>\n",
       "      <td>0.939050</td>\n",
       "      <td>0.008151</td>\n",
       "      <td>1.419929e-02</td>\n",
       "      <td>3.328642e-02</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G7KNmW9a75Y</td>\n",
       "      <td>talk to myself for hours  say things you do no...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 272, 4, 51, 18, 475,...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.517612e-01</td>\n",
       "      <td>0.404417</td>\n",
       "      <td>0.071435</td>\n",
       "      <td>1.885957e-01</td>\n",
       "      <td>8.379038e-02</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>vhumOLNSSJY</td>\n",
       "      <td>from how i  feel but i am too proud to open up...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 60, 54, 1, 2, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.794297e-07</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.726046e-07</td>\n",
       "      <td>1.692862e-07</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>vhumOLNSSJY</td>\n",
       "      <td>who i would be if i was happy  do not what is ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 70, 1, 52, 27, 50, 1...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.492461e-01</td>\n",
       "      <td>0.752897</td>\n",
       "      <td>0.023806</td>\n",
       "      <td>4.882041e-02</td>\n",
       "      <td>2.523041e-02</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>vhumOLNSSJY</td>\n",
       "      <td>like i do not  care what anyone else thinks  w...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.196371e-07</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.545425e-07</td>\n",
       "      <td>8.379989e-07</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>vhumOLNSSJY</td>\n",
       "      <td>to pick me up and pull me out this hole i am t...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 1001, 20, 4...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.898759e-02</td>\n",
       "      <td>0.956532</td>\n",
       "      <td>0.006740</td>\n",
       "      <td>3.617591e-03</td>\n",
       "      <td>4.122662e-03</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>vhumOLNSSJY</td>\n",
       "      <td>ooh  if i was happy</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.469118e-02</td>\n",
       "      <td>0.875880</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>7.153765e-02</td>\n",
       "      <td>3.081062e-02</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>976 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        video_id                                         transcript  \\\n",
       "0    G7KNmW9a75Y  we were good  we were gold  kind of dream that...   \n",
       "1    G7KNmW9a75Y  started to cry but then remembered i  i can bu...   \n",
       "2    G7KNmW9a75Y  yeah i can love me better than you can  can lo...   \n",
       "3    G7KNmW9a75Y  no remorse  no regret  i forgive every word yo...   \n",
       "4    G7KNmW9a75Y  talk to myself for hours  say things you do no...   \n",
       "..           ...                                                ...   \n",
       "971  vhumOLNSSJY  from how i  feel but i am too proud to open up...   \n",
       "972  vhumOLNSSJY  who i would be if i was happy  do not what is ...   \n",
       "973  vhumOLNSSJY  like i do not  care what anyone else thinks  w...   \n",
       "974  vhumOLNSSJY  to pick me up and pull me out this hole i am t...   \n",
       "975  vhumOLNSSJY                               ooh  if i was happy    \n",
       "\n",
       "                                         text_to_model  label  \\\n",
       "0    [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 77, 120, 117, ...      3   \n",
       "1    [[0, 0, 0, 0, 0, 0, 0, 0, 0, 177, 4, 639, 22, ...      1   \n",
       "2    [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1420, 1, 44, 8...      0   \n",
       "3    [[0, 0, 0, 0, 0, 0, 0, 93, 3268, 93, 1325, 1, ...      1   \n",
       "4    [[0, 0, 0, 0, 0, 0, 0, 0, 272, 4, 51, 18, 475,...      1   \n",
       "..                                                 ...    ...   \n",
       "971  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 60, 54, 1, 2, ...      1   \n",
       "972  [[0, 0, 0, 0, 0, 0, 0, 0, 70, 1, 52, 27, 50, 1...      1   \n",
       "973  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      1   \n",
       "974  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 1001, 20, 4...      1   \n",
       "975  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      1   \n",
       "\n",
       "     probability_sadness  probability_joy  probability_love  \\\n",
       "0           3.811742e-02         0.049064          0.000617   \n",
       "1           2.435994e-03         0.955003          0.011286   \n",
       "2           7.336176e-01         0.258982          0.000836   \n",
       "3           5.313131e-03         0.939050          0.008151   \n",
       "4           2.517612e-01         0.404417          0.071435   \n",
       "..                   ...              ...               ...   \n",
       "971         1.794297e-07         0.999994          0.000006   \n",
       "972         1.492461e-01         0.752897          0.023806   \n",
       "973         4.196371e-07         0.999992          0.000007   \n",
       "974         2.898759e-02         0.956532          0.006740   \n",
       "975         1.469118e-02         0.875880          0.007081   \n",
       "\n",
       "     probability_anger  probability_fear  emotion  \n",
       "0         9.033179e-01      8.883808e-03    Anger  \n",
       "1         1.009263e-02      2.118289e-02      Joy  \n",
       "2         6.150512e-03      4.139581e-04  Sadness  \n",
       "3         1.419929e-02      3.328642e-02      Joy  \n",
       "4         1.885957e-01      8.379038e-02      Joy  \n",
       "..                 ...               ...      ...  \n",
       "971       1.726046e-07      1.692862e-07      Joy  \n",
       "972       4.882041e-02      2.523041e-02      Joy  \n",
       "973       1.545425e-07      8.379989e-07      Joy  \n",
       "974       3.617591e-03      4.122662e-03      Joy  \n",
       "975       7.153765e-02      3.081062e-02      Joy  \n",
       "\n",
       "[976 rows x 10 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check output\n",
    "youtube_mv_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'text_to_model' column from the DataFrame:\n",
    "youtube_mv_transcripts = youtube_mv_transcripts.drop(columns = 'text_to_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the transcripts and text_to_model\n",
    "youtube_mv_transcripts['transcript'] = youtube_mv_transcripts.groupby('video_id')['transcript'].transform(lambda x : ' '.join(x))\n",
    "\n",
    "# Average the probabilities\n",
    "youtube_mv_transcripts['probability_sadness'] = youtube_mv_transcripts.groupby('video_id')['probability_sadness'].transform('mean')\n",
    "youtube_mv_transcripts['probability_joy'] = youtube_mv_transcripts.groupby('video_id')['probability_joy'].transform('mean')\n",
    "youtube_mv_transcripts['probability_love'] = youtube_mv_transcripts.groupby('video_id')['probability_love'].transform('mean')\n",
    "youtube_mv_transcripts['probability_anger'] = youtube_mv_transcripts.groupby('video_id')['probability_anger'].transform('mean')\n",
    "youtube_mv_transcripts['probability_fear'] = youtube_mv_transcripts.groupby('video_id')['probability_fear'].transform('mean')\n",
    "\n",
    "# Update the label\n",
    "youtube_mv_transcripts['label'] = youtube_mv_transcripts[['probability_sadness', 'probability_joy', 'probability_love', 'probability_anger', 'probability_fear']].idxmax(axis=1)\n",
    "\n",
    "# Create a dictionary to map probability column names to labels\n",
    "prob_to_label = {'probability_sadness': 0, 'probability_joy': 1, 'probability_love': 2, 'probability_anger': 3, 'probability_fear': 4}\n",
    "\n",
    "# Map the string labels to their integer representations\n",
    "youtube_mv_transcripts['label'] = youtube_mv_transcripts['label'].map(prob_to_label)\n",
    "\n",
    "#Update the emotions\n",
    "youtube_mv_transcripts['emotion'] = youtube_mv_transcripts['label'].map(emotion_dict)\n",
    "\n",
    "# Drop duplicates\n",
    "youtube_mv_transcripts.drop_duplicates(subset='video_id', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index:\n",
    "youtube_mv_transcripts = youtube_mv_transcripts.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>transcript</th>\n",
       "      <th>label</th>\n",
       "      <th>probability_sadness</th>\n",
       "      <th>probability_joy</th>\n",
       "      <th>probability_love</th>\n",
       "      <th>probability_anger</th>\n",
       "      <th>probability_fear</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G7KNmW9a75Y</td>\n",
       "      <td>we were good  we were gold  kind of dream that...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.185217</td>\n",
       "      <td>0.605823</td>\n",
       "      <td>0.024522</td>\n",
       "      <td>0.165062</td>\n",
       "      <td>0.019376</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oa_RSwwpPaA</td>\n",
       "      <td>for a while that it was rough but lately i hav...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.330111</td>\n",
       "      <td>0.335034</td>\n",
       "      <td>0.009799</td>\n",
       "      <td>0.069333</td>\n",
       "      <td>0.255724</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8UMnAIaBofo</td>\n",
       "      <td>tell death to us part tell death to us part i ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.299442</td>\n",
       "      <td>0.142625</td>\n",
       "      <td>0.108606</td>\n",
       "      <td>0.356857</td>\n",
       "      <td>0.092470</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iq8h3GEe22o</td>\n",
       "      <td>i do not like no whips and ch can not me down ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.412854</td>\n",
       "      <td>0.015061</td>\n",
       "      <td>0.014315</td>\n",
       "      <td>0.549594</td>\n",
       "      <td>0.008176</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H5v3kku4y6Q</td>\n",
       "      <td>holding me back  gravity holding me back  i wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.340206</td>\n",
       "      <td>0.305491</td>\n",
       "      <td>0.046790</td>\n",
       "      <td>0.092395</td>\n",
       "      <td>0.215117</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>uS_y_65CcpA</td>\n",
       "      <td>you want the girl with the small waist  and th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.471563</td>\n",
       "      <td>0.204420</td>\n",
       "      <td>0.008680</td>\n",
       "      <td>0.190082</td>\n",
       "      <td>0.125255</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>QBPE2fZsVYU</td>\n",
       "      <td>i have been dreaming about the west coast got ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.281542</td>\n",
       "      <td>0.412919</td>\n",
       "      <td>0.082388</td>\n",
       "      <td>0.133559</td>\n",
       "      <td>0.089593</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>JKrDdsgXuso</td>\n",
       "      <td>as you promised me that i was more than all th...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.325391</td>\n",
       "      <td>0.389652</td>\n",
       "      <td>0.040207</td>\n",
       "      <td>0.210264</td>\n",
       "      <td>0.034487</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>X0lRcz_IuPQ</td>\n",
       "      <td>i believe in ghosts  most people do not  i swe...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.226523</td>\n",
       "      <td>0.335049</td>\n",
       "      <td>0.005566</td>\n",
       "      <td>0.080700</td>\n",
       "      <td>0.352162</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>vhumOLNSSJY</td>\n",
       "      <td>dear god  please  hear me out  i know it is be...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.120968</td>\n",
       "      <td>0.658912</td>\n",
       "      <td>0.046208</td>\n",
       "      <td>0.150448</td>\n",
       "      <td>0.023464</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       video_id                                         transcript  label  \\\n",
       "0   G7KNmW9a75Y  we were good  we were gold  kind of dream that...      1   \n",
       "1   Oa_RSwwpPaA  for a while that it was rough but lately i hav...      1   \n",
       "2   8UMnAIaBofo  tell death to us part tell death to us part i ...      3   \n",
       "3   Iq8h3GEe22o  i do not like no whips and ch can not me down ...      3   \n",
       "4   H5v3kku4y6Q  holding me back  gravity holding me back  i wa...      0   \n",
       "..          ...                                                ...    ...   \n",
       "95  uS_y_65CcpA  you want the girl with the small waist  and th...      0   \n",
       "96  QBPE2fZsVYU  i have been dreaming about the west coast got ...      1   \n",
       "97  JKrDdsgXuso  as you promised me that i was more than all th...      1   \n",
       "98  X0lRcz_IuPQ  i believe in ghosts  most people do not  i swe...      4   \n",
       "99  vhumOLNSSJY  dear god  please  hear me out  i know it is be...      1   \n",
       "\n",
       "    probability_sadness  probability_joy  probability_love  probability_anger  \\\n",
       "0              0.185217         0.605823          0.024522           0.165062   \n",
       "1              0.330111         0.335034          0.009799           0.069333   \n",
       "2              0.299442         0.142625          0.108606           0.356857   \n",
       "3              0.412854         0.015061          0.014315           0.549594   \n",
       "4              0.340206         0.305491          0.046790           0.092395   \n",
       "..                  ...              ...               ...                ...   \n",
       "95             0.471563         0.204420          0.008680           0.190082   \n",
       "96             0.281542         0.412919          0.082388           0.133559   \n",
       "97             0.325391         0.389652          0.040207           0.210264   \n",
       "98             0.226523         0.335049          0.005566           0.080700   \n",
       "99             0.120968         0.658912          0.046208           0.150448   \n",
       "\n",
       "    probability_fear  emotion  \n",
       "0           0.019376      Joy  \n",
       "1           0.255724      Joy  \n",
       "2           0.092470    Anger  \n",
       "3           0.008176    Anger  \n",
       "4           0.215117  Sadness  \n",
       "..               ...      ...  \n",
       "95          0.125255  Sadness  \n",
       "96          0.089593      Joy  \n",
       "97          0.034487      Joy  \n",
       "98          0.352162     Fear  \n",
       "99          0.023464      Joy  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check final dataframe for youtube mv transcripts\n",
    "youtube_mv_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "hovertemplate": "Emotion=%{label}<br>Count=%{value}<extra></extra>",
         "labels": [
          "Love",
          "Joy",
          "Anger",
          "Sadness",
          "Fear"
         ],
         "legendgroup": "",
         "name": "",
         "showlegend": true,
         "textinfo": "label+value",
         "textposition": "inside",
         "type": "pie",
         "values": [
          2,
          35,
          30,
          24,
          9
         ]
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Emotion distribution of Music Videos"
        },
        "width": 500
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a pir chart to view the Emotion distribution of the 100 Music Videos\n",
    "# Create a copy of your DataFrame\n",
    "df = youtube_mv_transcripts.copy()\n",
    "\n",
    "# Count the occurrences of each emotion\n",
    "emotions_distribution = df['emotion'].value_counts().reset_index()\n",
    "emotions_distribution.columns = ['Emotion', 'Count']\n",
    "\n",
    "# Sort the DataFrame to make 'Joy' and 'Love' adjacent\n",
    "emotions_distribution = emotions_distribution.sort_values(by='Emotion', key=lambda col: col != 'Love')\n",
    "\n",
    "# Plot the pie chart\n",
    "fig = px.pie(emotions_distribution, names='Emotion', values='Count', title='Emotion distribution of Music Videos')\n",
    "fig.update_traces(textposition='inside', textinfo='label+value')\n",
    "\n",
    "# Update the layout with a specific width (in pixels)\n",
    "fig.update_layout(width=500)  # Adjust this value to make the figure narrower or wider\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data frame with emotions classified mv transcript as csv:\n",
    "youtube_mv_transcripts.to_csv('Data/youtube_mv_predicted_emotion.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<b> 4. Developing a rule-based recommender system that matches the emotions of each user comment to a list of 5 music videos. </b>\n",
    "* The rules for recommending the music videos differ based on whether the user is deemed to have positive or negative emotions. Here’s a summary of the steps:\n",
    "\n",
    "<b> Step Outline </b>\n",
    "\n",
    "1. **Define Emotions** categorize emotions into two groups: positive (Joy, Love) and negative (Sadness, Anger, Fear).\n",
    "2. **Get Original Video ID:** identify the video from which the user’s comment originated.\n",
    "3. **Filter Out Original Video:** exclude the original video from the list of potential recommendations.\n",
    "4. **Recommendation Rules** set up different rules for recommending music videos based on the user’s emotion.\n",
    "- **Positive Emotion**: If the user’s emotion is positive, look for music videos that evoke a similar emotion. For example, if a user’s comment is classified as ‘Joy’ with a certain probability, recommend 5 music videos whose ‘Joy’ probabilities are closest to that of the user’s comment. This is done using a method called KDTree, which is a way of finding the closest points (in this case, emotion probabilities) in a space.\n",
    "- **Negative Emotion**: If the user’s emotion is negative, look for music videos that can help uplift their mood. Form a ‘vector’ or a set of values for the comment, consisting of the probabilities of the three negative emotions. Do the same for all 100 music videos. Then, calculate the cosine similarity between the comment vector and each music video vector. Cosine similarity is a measure of how similar two vectors are, and in this case, it’s used to find music videos whose emotion probabilities are most similar to the user’s comment. However, the system will only consider those videos whose sum of negative emotion probabilities is at least 0.1 less than that of the user’s comment. This ensures that the recommended videos are slightly more positive than the user’s current mood. The 5 music videos with the smallest cosine similarity scores are recommended.\n",
    "5. **Print User Comment, Emotion, and Emotion Probability:** display the user’s comment, the detected emotion, and the probability of that emotion. For negative emotions, instead of probability of that emotion, display the user's comment sum of negative emotion probabilities\n",
    "6. **Print Recommended Video IDs and Their Emotion Probabilities:** display the IDs of the recommended videos and their corresponding emotion probabilities. For negative emotions, instead display the sum of the negative emotion probabilities and the cosine similarity scores.\n",
    "7. **Convert Video IDs to YouTube URLs:** convert the IDs of the recommended videos into YouTube URLs.\n",
    "8. **Return Recommended Videos:** return the recommended videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that Recommends music videos based on user comment and emotion, utilizing transcript and comment data\n",
    "def recommend_music_videos(user_comment, user_emotion, youtube_mv_transcripts, youtube_comments):\n",
    "    # Define the emotions\n",
    "    positive_emotions = ['Joy', 'Love']\n",
    "    negative_emotions = ['Sadness', 'Anger', 'Fear']\n",
    "    negative_probs = ['probability_' + emo.lower() for emo in negative_emotions]\n",
    "\n",
    "    # Get the video id of the original video the comment was scraped from\n",
    "    origin_video_id = user_comment['comment_origin_video_id']\n",
    "\n",
    "    # Filter out the original video from the transcripts dataframe\n",
    "    filtered_transcripts = youtube_mv_transcripts[youtube_mv_transcripts['video_id'] != origin_video_id]\n",
    "\n",
    "    recommended_videos = None\n",
    "    if user_emotion in positive_emotions:\n",
    "        # For positive emotions, find the 5 closest emotion probabilities\n",
    "        tree = KDTree(filtered_transcripts[['probability_' + user_emotion.lower()]])\n",
    "        dist, idx = tree.query([[user_comment['probability_' + user_emotion.lower()]]], k=min(5, len(filtered_transcripts)))\n",
    "        recommended_videos = filtered_transcripts.iloc[idx[0]]\n",
    "\n",
    "        # Print the user comment, emotion, and emotion probability\n",
    "        print(f\"User comment: {user_comment['text']}\")\n",
    "        print(f\"User emotion: {user_emotion}\")\n",
    "        print(f\"User emotion probability: {user_comment['probability_' + user_emotion.lower()]}\")\n",
    "\n",
    "    elif user_emotion in negative_emotions:\n",
    "        # For negative emotions, calculate cosine similarity\n",
    "        user_vector = user_comment[negative_probs].values.reshape(1, -1)\n",
    "        \n",
    "        # Filter out videos with sum of negative emotion probabilities that are not at least 0.1 than the user's comment\n",
    "        filtered_transcripts = filtered_transcripts[\n",
    "            (filtered_transcripts[negative_probs].sum(axis=1) < user_comment[negative_probs].sum() - 0.1)\n",
    "        ]\n",
    "\n",
    "        # Calculate cosine similarity\n",
    "        filtered_transcripts['cosine_similarity'] = filtered_transcripts.apply(lambda row: cosine_similarity(user_vector, row[negative_probs].values.reshape(1, -1))[0][0], axis=1)\n",
    "\n",
    "        # Find the 5 closest emotion probabilities\n",
    "        if len(filtered_transcripts) > 0:\n",
    "            recommended_videos = filtered_transcripts.nsmallest(5, 'cosine_similarity')\n",
    "        else:\n",
    "            print(\"There are currently no videos to recommend based on the user's current emotion level.\")\n",
    "            return\n",
    "\n",
    "        # Print the user comment, emotion, and sum of negative emotion probabilities\n",
    "        print(f\"User comment: {user_comment['text']}\")\n",
    "        print(f\"User emotion: {user_emotion}\")\n",
    "        print(f\"User sum of negative emotion probabilities: {user_comment[negative_probs].sum()}\")\n",
    "\n",
    "    # Print the recommended video IDs and their emotion probabilities\n",
    "    video_ids = recommended_videos['video_id'].tolist()\n",
    "    print(f\"Recommended video IDs: {video_ids}\")\n",
    "    if user_emotion in positive_emotions:\n",
    "        print(f\"Recommended video {user_emotion} probabilities: {recommended_videos['probability_' + user_emotion.lower()].tolist()}\")\n",
    "    else:\n",
    "        print(f\"Recommended video sum of negative emotion probabilities: {recommended_videos[negative_probs].sum(axis=1).tolist()}\")\n",
    "        print(f\"Recommended video cosine similarity scores: {recommended_videos['cosine_similarity'].tolist()}\")\n",
    "\n",
    "    # Convert the video IDs to YouTube URLs\n",
    "    youtube_urls = ['https://www.youtube.com/watch?v=' + video_id for video_id in video_ids]\n",
    "    print(f\"Recommended YouTube URLs: {youtube_urls}\")\n",
    "\n",
    "    return recommended_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that recommends music videos based on user comment and emotion using the specified index\n",
    "def recommend_music_videos_by_index(index, youtube_mv_transcripts = youtube_mv_transcripts, youtube_comments = youtube_comments):\n",
    "    # Get the user comment and emotion based on the index\n",
    "    user_comment = youtube_comments.iloc[index]\n",
    "    user_emotion = user_comment['emotion']\n",
    "\n",
    "    # Call the original function with the fetched comment and emotion\n",
    "    recommend_music_videos(user_comment, user_emotion, youtube_mv_transcripts, youtube_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User comment: i lost my great grandpa even though i could not see him that much he was amazing and this song just makes me feel everything that i felt when i lost him\n",
      "User emotion: Sadness\n",
      "User sum of negative emotion probabilities: 0.9998680949211121\n",
      "Recommended video IDs: ['qod03PVTLqk', 'AoAm4om0wTs', 'm4_9TFeMfJE', 'U6n2NcJ7rLc', 'je0roKRn3nY']\n",
      "Recommended video sum of negative emotion probabilities: [0.7952914237976074, 0.6725053787231445, 0.6448014974594116, 0.7460570335388184, 0.6020493507385254]\n",
      "Recommended video cosine similarity scores: [0.03645788368329114, 0.06054643781415544, 0.08317993742267622, 0.09016767111904954, 0.1102377029922241]\n",
      "Recommended YouTube URLs: ['https://www.youtube.com/watch?v=qod03PVTLqk', 'https://www.youtube.com/watch?v=AoAm4om0wTs', 'https://www.youtube.com/watch?v=m4_9TFeMfJE', 'https://www.youtube.com/watch?v=U6n2NcJ7rLc', 'https://www.youtube.com/watch?v=je0roKRn3nY']\n"
     ]
    }
   ],
   "source": [
    "# call the function with an index\n",
    "recommend_music_videos_by_index(27386)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that retrieves the transcript for a given video ID\n",
    "def get_transcript(video_id, youtube_mv_transcripts = youtube_mv_transcripts):\n",
    "    transcript = youtube_mv_transcripts[youtube_mv_transcripts['video_id'] == video_id]['transcript'].values[0]\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'golden  golden  golden  as i open my eyes  hold it  focus  hoping  take me back to the light  i know you were way too bright for me  i am hopeless  broken  so you wait for me in the sky  browns my skin just right  you are so golden  you are so golden  i am out of my head  and i know that you are scared  because hearts get broken  i do not want to be alone  i do not want to be alone  when it ends  do not want to let you know  i do not want to be alone  but i  i can feel it take a hold  i can feel you take control  of who i am and all i have ever known  loving you the antidote  golden  you are so golden  i do not want to be alone  you are so golden  you are so golden  i am out of my head  and i know that you are scared  because hearts get broken  i know that you are scared  because i am so open  you are so golden  i do not want to be alone  you are so golden  you are so golden  you are so golden  i am out of my head  and i know that you are scared  because hearts get broken '"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call function to get transcript of music video\n",
    "get_transcript('P3cffdsEXXw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<b> 5. Evaluation of Recommender System. </b>\n",
    "\n",
    "The Emotion-centric recommender system I have build is functional but has room for improvement. The system’s ability to classify emotions in music videos and user comments is not always accurate. For instance, some music videos and comments that seem negative are classified as positive and vice versa. Furthermore, the system sometimes recommends music videos that don’t seem to match the user’s emotional state. For example, it might recommend a sad song to a user expressing joy or a sadder song to a user who is already feeling sad.\n",
    "\n",
    "## Potential Weaknesses\n",
    "\n",
    "1. **Limited Training Data:** The classification model was trained on a labeled dataset of tweets from Kaggle. This might not be representative of the language used in YouTube comments or music video lyrics.\n",
    "2. **Complexity of Emotions:** Emotions can overlap and it can be challenging to discern emotions from text. A comment or a song could contain elements of multiple emotions, making it difficult for the model to classify accurately.\n",
    "3. **Limited Scope of Analysis:** The system only analyzes the transcripts of the music videos, which might not fully capture the emotional content of the songs. The actual audio signals and the visuals of the music videos are not considered.\n",
    "4. **Word Embeddings Limitations:** The GloVe word embeddings used in the model capture semantic relationships between words but are static and do not consider the context in which a word appears. This means the same word will have the same representation regardless of its context, which could limit the model’s ability to fully capture context-driven semantic word vectorization.\n",
    "5. **Model Complexity:** The DistilBERT model, a transformer-based model, was expected to perform well due to its ability to understand the semantic meaning of words based on their context. However, it performed poorly, possibly due to its complexity and insufficient training.\n",
    "\n",
    "## Future Work\n",
    "\n",
    "- **Expand Training Data:** Consider increasing the data pool to include labeled comments from other social media platforms. This could help the model better understand the language used in YouTube comments and music video lyrics.\n",
    "- **Explore Unsupervised Learning:** Explore using unsupervised learning to cluster the emotions of the text. This could potentially improve the accuracy of emotion classification.\n",
    "- **Incorporate Audio and Visual Analysis:** Consider incorporating analysis of the audio signals and visuals of the music videos. This could provide a more comprehensive understanding of the emotional content of the songs.\n",
    "- **Improve Word Embeddings:** Consider using context-aware word embeddings that can capture the semantic meaning of words based on their context.\n",
    "- **Tune DistilBERT Model:** Future work could explore tuning the DistilBERT model or providing it with more training data to improve its performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
